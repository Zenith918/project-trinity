#!/usr/bin/env python3
"""
Build TensorRT-LLM Engine for MOSS-Speech
==========================================

âš ï¸ è­¦å‘Š: æœ¬æ–‡ä»¶åŒ…å«å…³é”®çš„æ¶æ„çº¦æŸï¼Œä¿®æ”¹å‰è¯·é˜…è¯»:
   /workspace/docs/moss-speech/PITFALLS_AND_SOLUTIONS.md

å…³é”®å‚æ•° (ç¦æ­¢ä¿®æ”¹):
-------------------
- TOTAL_LAYERS = 40
- max_seq_len = 2048 (æ‰©å±•éœ€è°¨æ…ï¼Œè§æ–‡æ¡£)
"""

import os
import sys
import json
import inspect

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”´ å…³é”®å¸¸é‡ - ç¦æ­¢ä¿®æ”¹ï¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOTAL_LAYERS = 40  # 32 shared + 4 text + 4 audio

# é»˜è®¤ max_seq_len = 2048
# âš ï¸ æ‰©å±•åˆ° 4096 éœ€è¦:
#    1. å¯ç”¨ FP8 é‡åŒ–
#    2. æˆ–ä½¿ç”¨å¤šå¡åˆ†æµ
#    3. æˆ–ç¡®ä¿ç³»ç»Ÿæœ‰ > 300GB RAM
DEFAULT_MAX_SEQ_LEN = 2048


def verify_build_prerequisites():
    """
    [ARCH_GUARD] éªŒè¯æ„å»ºå‰ç½®æ¡ä»¶
    """
    assert TOTAL_LAYERS == 40, \
        f"[ARCH_GUARD] FATAL: TOTAL_LAYERS={TOTAL_LAYERS}, å¿…é¡»ä¸º 40ï¼"
    
    print("[ARCH_GUARD] âœ… æ„å»ºå‰ç½®æ¡ä»¶éªŒè¯é€šè¿‡")


def build_moss_speech_engine(
    checkpoint_dir: str,
    output_dir: str,
    max_batch_size: int = 1,
    max_input_len: int = 1024,
    max_seq_len: int = DEFAULT_MAX_SEQ_LEN,
):
    """
    Build TensorRT-LLM engine for MOSS-Speech
    
    Parameters
    ----------
    checkpoint_dir : str
        Checkpoint ç›®å½•ï¼ŒåŒ…å« config.json å’Œ rank0.safetensors
    output_dir : str
        è¾“å‡ºç›®å½•
    max_batch_size : int
        æœ€å¤§ batch size
    max_input_len : int
        æœ€å¤§è¾“å…¥é•¿åº¦
    max_seq_len : int
        æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆåŒ…æ‹¬ç”Ÿæˆçš„ tokenï¼‰
        âš ï¸ å½“å‰é»˜è®¤ 2048ï¼Œæ‰©å±•éœ€è°¨æ…
    """
    import psutil
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # [ARCH_GUARD] æ„å»ºå‰éªŒè¯
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    verify_build_prerequisites()
    
    print(f"=" * 60)
    print(f"[ARCH_GUARD] Building MOSS-Speech Engine")
    print(f"[ARCH_GUARD] 40-Layer Virtual Linearization Active")
    print(f"=" * 60)
    print(f"  Checkpoint: {checkpoint_dir}")
    print(f"  Output: {output_dir}")
    print(f"  max_batch_size: {max_batch_size}")
    print(f"  max_input_len: {max_input_len}")
    print(f"  max_seq_len: {max_seq_len}")
    print(f"  TOTAL_LAYERS: {TOTAL_LAYERS}")
    print(f"=" * 60)
    
    # æ£€æŸ¥åˆå§‹å†…å­˜
    mem = psutil.virtual_memory()
    print(f"åˆå§‹å†…å­˜: {mem.percent:.1f}% ({mem.used/1024**3:.1f}GB/{mem.total/1024**3:.1f}GB)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # å¯¼å…¥ TensorRT-LLM
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    import tensorrt_llm
    from tensorrt_llm.builder import BuildConfig
    from tensorrt_llm.plugin import PluginConfig
    
    # å¯¼å…¥æ¨¡å‹å®šä¹‰
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    from moss_trtllm_model import MossSpeechForCausalLM, verify_model_architecture
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # åŠ è½½é…ç½®
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    config_path = os.path.join(checkpoint_dir, "config.json")
    with open(config_path, 'r') as f:
        config_dict = json.load(f)
    
    # å…¼å®¹ä¸¤ç§é…ç½®æ ¼å¼
    if 'pretrained_config' in config_dict:
        config_dict['pretrained_config']['num_hidden_layers'] = TOTAL_LAYERS
        pretrained_config = config_dict['pretrained_config']
    else:
        config_dict['num_hidden_layers'] = TOTAL_LAYERS
        pretrained_config = config_dict
    
    print(f"[ARCH_GUARD] âœ… å¼ºåˆ¶ num_hidden_layers = {TOTAL_LAYERS}")
    
    # ä¿å­˜ä¿®æ”¹åçš„é…ç½®
    modified_config_path = os.path.join(output_dir, "config.json")
    with open(modified_config_path, 'w') as f:
        json.dump(config_dict, f, indent=2)
    print(f"âœ… ä¿å­˜ä¿®æ”¹åçš„é…ç½®åˆ°: {modified_config_path}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # åŠ è½½æ¨¡å‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print(f"\nåŠ è½½æ¨¡å‹...")
    model = MossSpeechForCausalLM.from_checkpoint(checkpoint_dir)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # [ARCH_GUARD] éªŒè¯æ¨¡å‹æ¶æ„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    verify_model_architecture(model)
    
    # é¢å¤–çš„é™æ€æ–­è¨€
    assert model.config.num_hidden_layers == 40, \
        "[ARCH_GUARD] FATAL: ç‰©ç†å±‚æ•°å¿…é¡»ä¸º40ï¼Œä¸¥ç¦ä¿®æ”¹ä¸ºQwené»˜è®¤çš„32å±‚ï¼"
    
    # æ£€æŸ¥è™šæ‹Ÿçº¿æ€§åŒ–ä¾èµ–é“¾
    source = inspect.getsource(model.transformer.forward)
    assert "1e-4" in source or "1e-04" in source or "VIRTUAL_LINEARIZATION_EPSILON" in source, \
        "[ARCH_GUARD] FATAL: è™šæ‹Ÿåºåˆ—åŒ–ä¾èµ–é“¾ä¸¢å¤±ï¼ŒGeneration Phase å°†å´©æºƒï¼"
    
    # æ£€æŸ¥å†…å­˜
    mem = psutil.virtual_memory()
    print(f"æ¨¡å‹åŠ è½½åå†…å­˜: {mem.percent:.1f}%")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # é…ç½®æ’ä»¶
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    plugin_config = PluginConfig()
    plugin_config.gpt_attention_plugin = "float16"
    plugin_config.gemm_plugin = "float16"
    plugin_config.paged_kv_cache = True   # ğŸ”´ å¿…é¡»å¯ç”¨ PagedAttention
    plugin_config.remove_input_padding = True
    plugin_config.context_fmha = True
    
    # è®¡ç®— KV cache å—æ•°
    tokens_per_block = 64
    max_blocks_per_seq = (max_seq_len + tokens_per_block - 1) // tokens_per_block
    print(f"max_blocks_per_seq: {max_blocks_per_seq} (tokens_per_block={tokens_per_block})")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ„å»ºé…ç½®
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    build_config = BuildConfig(
        max_batch_size=max_batch_size,
        max_input_len=max_input_len,
        max_seq_len=max_seq_len,
        max_num_tokens=max_batch_size * max_input_len,
        plugin_config=plugin_config,
        strongly_typed=True,  # å¯ç”¨å¼ºç±»å‹ä»¥å‡å°‘å†…å­˜
    )
    
    print(f"[ARCH_GUARD] âœ… æ¨¡å‹å±‚æ•°å·²è®¾ç½®ä¸º {TOTAL_LAYERS}")
    
    # æ£€æŸ¥å†…å­˜
    mem = psutil.virtual_memory()
    print(f"æ„å»ºé…ç½®åå†…å­˜: {mem.percent:.1f}%")
    
    if mem.percent > 80:
        print(f"âš ï¸ å†…å­˜è¾ƒé«˜ ({mem.percent:.1f}%)ï¼Œç»§ç»­æ„å»º...")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ„å»º Engine
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print(f"\nå¼€å§‹æ„å»º Engine...")
    print(f"è¿™å¯èƒ½éœ€è¦ 10-30 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    try:
        engine = tensorrt_llm.builder.build(model, build_config)
        
        # ä¿å­˜ Engine
        engine_path = os.path.join(output_dir, "rank0.engine")
        print(f"\nä¿å­˜ Engine åˆ°: {engine_path}")
        
        with open(engine_path, 'wb') as f:
            f.write(engine.engine)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ä¿å­˜é…ç½®ï¼ˆåŒ…å«æ¶æ„ä¿¡æ¯ï¼‰
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        engine_config = {
            "pretrained_config": pretrained_config,
            "build_config": {
                "max_batch_size": max_batch_size,
                "max_input_len": max_input_len,
                "max_seq_len": max_seq_len,
                "num_layers": TOTAL_LAYERS,
                "paged_kv_cache": True,
                "tokens_per_block": tokens_per_block,
                "max_blocks_per_seq": max_blocks_per_seq,
            },
            # [ARCH_GUARD] è®°å½•æ¶æ„ä¿¡æ¯
            "arch_guard": {
                "virtual_linearization": True,
                "epsilon": "1e-4",
                "total_layers": TOTAL_LAYERS,
                "audio_start_idx": 36,
            }
        }
        
        engine_config_path = os.path.join(output_dir, "config.json")
        with open(engine_config_path, 'w') as f:
            json.dump(engine_config, f, indent=2)
        
        print(f"\n" + "=" * 60)
        print(f"[ARCH_GUARD] âœ…âœ…âœ… Engine built successfully! âœ…âœ…âœ…")
        print(f"[ARCH_GUARD] 40-Layer Virtual Linearization Active")
        print(f"=" * 60)
        print(f"Engine: {engine_path}")
        print(f"Config: {engine_config_path}")
        
        # æœ€ç»ˆå†…å­˜
        mem = psutil.virtual_memory()
        print(f"æœ€ç»ˆå†…å­˜: {mem.percent:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æ„å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Build MOSS-Speech TensorRT-LLM Engine")
    parser.add_argument("--checkpoint_dir", default="/workspace/models/MOSS-Speech-TRTLLM-Full",
                        help="Checkpoint ç›®å½•")
    parser.add_argument("--output_dir", default="/workspace/models/MOSS-Speech-Engine-v9",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--max_batch_size", type=int, default=1,
                        help="æœ€å¤§ batch size")
    parser.add_argument("--max_input_len", type=int, default=1024,
                        help="æœ€å¤§è¾“å…¥é•¿åº¦")
    parser.add_argument("--max_seq_len", type=int, default=DEFAULT_MAX_SEQ_LEN,
                        help=f"æœ€å¤§åºåˆ—é•¿åº¦ (é»˜è®¤: {DEFAULT_MAX_SEQ_LEN})")
    args = parser.parse_args()
    
    # æ‰“å°è­¦å‘Š
    if args.max_seq_len > DEFAULT_MAX_SEQ_LEN:
        print(f"âš ï¸ è­¦å‘Š: max_seq_len={args.max_seq_len} > {DEFAULT_MAX_SEQ_LEN}")
        print(f"   æ‰©å±• max_seq_len å¯èƒ½å¯¼è‡´ OOMï¼")
        print(f"   è¯·ç¡®ä¿:")
        print(f"     1. ç³»ç»Ÿæœ‰è¶³å¤Ÿå†…å­˜ (> 300GB)")
        print(f"     2. æˆ–å¯ç”¨ FP8 é‡åŒ–")
        print(f"     3. æˆ–ä½¿ç”¨å¤šå¡åˆ†æµ")
        print()
    
    build_moss_speech_engine(
        checkpoint_dir=args.checkpoint_dir,
        output_dir=args.output_dir,
        max_batch_size=args.max_batch_size,
        max_input_len=args.max_input_len,
        max_seq_len=args.max_seq_len,
    )
