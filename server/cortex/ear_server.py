"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  üëÇ CORTEX-EAR SERVER (Á´ØÂè£ 9002)                                             ‚ïë
‚ïë  Âè™Ë¥üË¥£ ASR ËØ≠Èü≥ËØÜÂà´ (FunASR/SenseVoice)                                      ‚ïë
‚ïë  ÂèØÁã¨Á´ãÈáçÂêØÔºå‰∏çÂΩ±Âìç Brain Âíå Mouth                                            ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  üí° ÂºÄÂèëÊèêÁ§∫: Ê≠§ÊúçÂä°ÊûÅËΩªÈáèÔºåÈáçÂêØÂè™ÈúÄ ~5s                                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

import os
import io
import wave
import asyncio
import subprocess
import numpy as np
from loguru import logger

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß Ëá™Âä®Á´ØÂè£Ê∏ÖÁêÜ
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
SERVICE_PORT = 9002

def kill_port(port: int):
    """ÊùÄÊéâÂç†Áî®ÊåáÂÆöÁ´ØÂè£ÁöÑËøõÁ®ã"""
    try:
        subprocess.run(f"fuser -k {port}/tcp 2>/dev/null || true", shell=True, timeout=5)
    except Exception:
        pass

kill_port(SERVICE_PORT)
from fastapi import FastAPI, UploadFile, File, HTTPException
from contextlib import asynccontextmanager
from typing import Tuple

# ÂÖ®Â±ÄÊ®°ÂûãÂÆû‰æã
ear = None

class EarHandler:
    """FunASR (SenseVoice) ËØ≠Èü≥ËØÜÂà´Â§ÑÁêÜÂô®"""
    
    def __init__(self, model_name: str = "iic/SenseVoiceSmall", device: str = "cuda:0"):
        self.model_name = model_name
        self.device = device
        self.model = None
        self.is_ready = False
        self._lock = asyncio.Lock()
    
    async def initialize(self):
        logger.info(f"Ê≠£Âú®ÂàùÂßãÂåñ FunASR: {self.model_name}")
        try:
            from funasr import AutoModel
            self.model = AutoModel(
                model=self.model_name,
                trust_remote_code=True,
                device=self.device
            )
            self.is_ready = True
            logger.success(f"FunASR ÂàùÂßãÂåñÊàêÂäü")
            return True
        except Exception as e:
            logger.error(f"FunASR ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            return False
    
    async def transcribe(self, audio_data: np.ndarray, sample_rate: int = 16000) -> dict:
        """ËØ≠Èü≥ËΩ¨ÊñáÂ≠ó"""
        if not self.is_ready:
            raise RuntimeError("EarHandler Êú™ÂàùÂßãÂåñ")
        
        async with self._lock:
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, self._inference, audio_data, sample_rate)
            return result
    
    def _inference(self, audio_data: np.ndarray, sample_rate: int) -> dict:
        result = self.model.generate(
            input=audio_data,
            cache={},
            language="auto",
            use_itn=True,
            batch_size_s=60
        )
        
        text = result[0]["text"] if result else ""
        emotion, clean_text = self._parse_emotion(text)
        
        return {
            "text": clean_text,
            "raw_text": text,
            "emotion": emotion,
            "language": "zh" if any('\u4e00' <= c <= '\u9fff' for c in clean_text) else "en"
        }
    
    def _parse_emotion(self, text: str) -> Tuple[str, str]:
        emotion_map = {
            "HAPPY": "happy", "SAD": "sad", "ANGRY": "angry",
            "FEARFUL": "fearful", "DISGUSTED": "disgusted",
            "SURPRISED": "surprised", "NEUTRAL": "neutral"
        }
        emotion = "neutral"
        clean_text = text
        for tag, name in emotion_map.items():
            if f"<|{tag}|>" in text:
                emotion = name
                clean_text = text.replace(f"<|{tag}|>", "").strip()
                break
        # Ê∏ÖÁêÜÂÖ∂‰ªñÊ†áÁ≠æ
        for tag in ["<|zh|>", "<|en|>", "<|EMO_UNKNOWN|>", "<|Speech|>", "<|withitn|>"]:
            clean_text = clean_text.replace(tag, "")
        return emotion, clean_text.strip()
    
    async def shutdown(self):
        if self.model:
            del self.model
            self.model = None
        self.is_ready = False


@asynccontextmanager
async def lifespan(app: FastAPI):
    global ear
    logger.info("üëÇ Cortex-Ear Server ÂêØÂä®‰∏≠...")
    
    ear = EarHandler()
    await ear.initialize()
    
    logger.success("‚úÖ Ear Server Â∞±Áª™ (Á´ØÂè£ 9002)")
    yield
    
    logger.info("üõë Ear Server ÂÖ≥Èó≠‰∏≠...")
    if ear:
        await ear.shutdown()

app = FastAPI(lifespan=lifespan, title="Cortex-Ear")

@app.get("/health")
async def health():
    return {
        "service": "ear",
        "status": "ok" if ear and ear.is_ready else "loading",
        "model": "SenseVoiceSmall"
    }

@app.post("/transcribe")
async def transcribe(file: UploadFile = File(...)):
    """
    ËØ≠Èü≥ËΩ¨ÊñáÂ≠ó
    
    Êé•Âèó: WAV/PCM Èü≥È¢ëÊñá‰ª∂
    ËøîÂõû: {"text": "ËØÜÂà´ÁªìÊûú", "emotion": "ÊÉÖÊÑü", "language": "ËØ≠Ë®Ä"}
    """
    if not ear or not ear.is_ready:
        raise HTTPException(status_code=503, detail="Ear not ready")
    
    try:
        # ËØªÂèñÈü≥È¢ë
        audio_bytes = await file.read()
        
        # Ëß£Êûê WAV
        with io.BytesIO(audio_bytes) as wav_io:
            with wave.open(wav_io, 'rb') as wf:
                sample_rate = wf.getframerate()
                n_channels = wf.getnchannels()
                sampwidth = wf.getsampwidth()
                frames = wf.readframes(wf.getnframes())
        
        # ËΩ¨Êç¢‰∏∫ numpy
        if sampwidth == 2:
            audio_array = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
        else:
            audio_array = np.frombuffer(frames, dtype=np.float32)
        
        # ÂçïÂ£∞ÈÅì
        if n_channels > 1:
            audio_array = audio_array.reshape(-1, n_channels).mean(axis=1)
        
        # ËØÜÂà´
        result = await ear.transcribe(audio_array, sample_rate)
        return result
        
    except Exception as e:
        logger.error(f"ËØ≠Èü≥ËØÜÂà´Â§±Ë¥•: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    kill_port(SERVICE_PORT)
    uvicorn.run(app, host="0.0.0.0", port=SERVICE_PORT)





