"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âš ï¸  å·²å¼ƒç”¨ - è¯·ä½¿ç”¨ä¸‰è„‘åˆ†ç«‹æ¶æ„  âš ï¸                                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  ğŸ›ï¸ æ–°æ¶æ„ (2026å¹´1æœˆ): ä¸‰è„‘åˆ†ç«‹ (Trinity Cortex Split)                       â•‘
â•‘                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â•‘
â•‘  â”‚ brain_server.py â”‚ â”‚ mouth_server.py â”‚ â”‚ ear_server.py   â”‚                 â•‘
â•‘  â”‚ ç«¯å£ 9000       â”‚ â”‚ ç«¯å£ 9001       â”‚ â”‚ ç«¯å£ 9002       â”‚                 â•‘
â•‘  â”‚ ğŸ§  LLM          â”‚ â”‚ ğŸ‘„ TTS          â”‚ â”‚ ğŸ‘‚ ASR          â”‚                 â•‘
â•‘  â”‚ é‡å¯ ~90s       â”‚ â”‚ é‡å¯ ~20s       â”‚ â”‚ é‡å¯ ~5s        â”‚                 â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â•‘
â•‘                                                                              â•‘
â•‘  ä¼˜åŠ¿: æ¯ä¸ªæœåŠ¡å¯ç‹¬ç«‹é‡å¯ï¼Œäº’ä¸å¹²æ‰°ï¼                                           â•‘
â•‘                                                                              â•‘
â•‘  ğŸš« æœ¬æ–‡ä»¶ (main.py) å·²å¼ƒç”¨ï¼Œè¯·å‹¿ä½¿ç”¨                                          â•‘
â•‘  âœ… ä½¿ç”¨: python -m uvicorn server.cortex.brain_server:app --port 9000       â•‘
â•‘  âœ… ä½¿ç”¨: python -m uvicorn server.cortex.mouth_server:app --port 9001       â•‘
â•‘  âœ… ä½¿ç”¨: python -m uvicorn server.cortex.ear_server:app --port 9002         â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import socket
import psutil
from loguru import logger
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from contextlib import asynccontextmanager
import json

# ==========================================
# 0. ç«¯å£æŠ¢å ä¸æ¸…ç† (Port Guard)
# ==========================================
def ensure_port_available(port: int):
    """ç¡®ä¿ç«¯å£å¯ç”¨ï¼Œå¦‚æœè¢«å ç”¨åˆ™æ€æ‰å ç”¨è¿›ç¨‹"""
    logger.info(f"ğŸ›¡ï¸ æ£€æŸ¥ç«¯å£ {port}...")
    try:
        # å°è¯•ç»‘å®šç«¯å£
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.bind(('0.0.0.0', port))
        sock.close()
        logger.success(f"ç«¯å£ {port} å¯ç”¨")
        return
    except OSError:
        logger.warning(f"ç«¯å£ {port} è¢«å ç”¨ï¼Œæ­£åœ¨å¯»æ‰¾å ç”¨è€…...")
    
    # æŸ¥æ‰¾å¹¶æ€æ‰å ç”¨è¿›ç¨‹
    killed = False
    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
        try:
            for conn in proc.connections(kind='inet'):
                if conn.laddr.port == port:
                    logger.warning(f"å‘ç°å ç”¨è¿›ç¨‹: PID={proc.info['pid']} Name={proc.info['name']}")
                    proc.kill()
                    killed = True
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue
            
    if killed:
        logger.success(f"å·²æ¸…ç†å ç”¨ç«¯å£ {port} çš„è¿›ç¨‹")
    else:
        logger.error(f"æ— æ³•æ¸…ç†ç«¯å£ {port}ï¼Œå¯èƒ½æƒé™ä¸è¶³æˆ–é Python è¿›ç¨‹å ç”¨")

# åœ¨å¯¼å…¥å¤§æ¨¡å‹å‰æ‰§è¡Œæ£€æŸ¥
ensure_port_available(9000)

# å¼ºåˆ¶æ·»åŠ  CosyVoice è·¯å¾„
COSYVOICE_PATH = "/workspace/CosyVoice"
if os.path.exists(COSYVOICE_PATH) and COSYVOICE_PATH not in sys.path:
    sys.path.insert(0, COSYVOICE_PATH)

from .models.brain import BrainHandler
from .models.mouth import MouthHandler

# å…¨å±€æ¨¡å‹å®ä¾‹
brain = None
mouth = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global brain, mouth
    logger.info("ğŸ§  Cortex Model Server æ­£åœ¨å¯åŠ¨...")
    
    # 1. åŠ è½½ Brain (Qwen2.5-VL)
    # æ˜¾å­˜å ç”¨æœ€å¤§ï¼Œä¼˜å…ˆåŠ è½½
    try:
        brain = BrainHandler()
        await brain.initialize()
    except Exception as e:
        logger.error(f"Brain åŠ è½½å¤±è´¥: {e}")
        
    # 2. åŠ è½½ Mouth (CosyVoice 3.0)
    try:
        mouth = MouthHandler()
        await mouth.initialize()
    except Exception as e:
        logger.error(f"Mouth åŠ è½½å¤±è´¥: {e}")
        
    logger.success("âœ… Cortex Server å°±ç»ª")
    yield
    
    # æ¸…ç†
    logger.info("ğŸ›‘ Cortex Server å…³é—­ä¸­...")
    if brain: await brain.shutdown()
    if mouth: await mouth.shutdown()

app = FastAPI(lifespan=lifespan)

@app.get("/health")
async def health_check():
    status = {
        "brain": brain.is_ready if brain else False,
        "mouth": mouth.is_ready if mouth else False
    }
    return {"status": "ok", "modules": status}

@app.post("/brain/chat")
async def chat(request: dict):
    """éæµå¼èŠå¤© (å…¼å®¹æ—§æ¥å£)"""
    if not brain or not brain.is_ready:
        return {"error": "Brain not ready"}
    return await brain.generate(request)

@app.post("/brain/chat/stream")
async def chat_stream(request: dict):
    """
    çœŸæ­£çš„æµå¼èŠå¤© - SSE (Server-Sent Events)
    æ¯ä¸ª token ç”Ÿæˆåç«‹å³å‘é€ï¼ŒTTFT ç›®æ ‡ <200ms
    """
    if not brain or not brain.is_ready:
        return {"error": "Brain not ready"}
    
    async def event_generator():
        try:
            async for token in brain.generate_stream(request):
                # SSE æ ¼å¼: data: {json}\n\n
                yield f"data: {json.dumps({'token': token})}\n\n"
            # å‘é€ç»“æŸæ ‡è®°
            yield f"data: {json.dumps({'done': True})}\n\n"
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨ nginx ç¼“å†²
        }
    )

@app.post("/mouth/tts")
async def tts(request: dict):
    if not mouth or not mouth.is_ready:
        return {"error": "Mouth not ready"}
    
    result = await mouth.synthesize(request)
    
    if "error" in result:
        return result
    
    # è¿”å› WAV éŸ³é¢‘
    import io
    return StreamingResponse(
        io.BytesIO(result["audio_bytes"]),
        media_type="audio/wav",
        headers={"Content-Disposition": "attachment; filename=speech.wav"}
    )
