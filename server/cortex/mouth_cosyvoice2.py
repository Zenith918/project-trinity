#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CosyVoice2 0.5B FastAPI æœåŠ¡
ç«¯å£: 9005
ç¯å¢ƒ: cosyvoice2_env (torch 2.3.1, flash-attn 2.5.8)

æ ¸å¿ƒç‰¹æ€§:
- çœŸæµå¼è¾“å‡º (stream=True)
- 44.1kHz é‡‡æ ·ç‡ (ä» 22.05kHz é‡é‡‡æ ·)
- FP16 ç²¾åº¦
- é¢„çƒ­æœºåˆ¶ç¡®ä¿ TTFA < 300ms
- RTF å®æ—¶ç›‘æ§
"""
import os
import sys
import time
import io
import wave

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã€é“å¾‹ã€‘æ—¥å¿—é…ç½® - å¿…é¡»åŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œç»ˆç«¯ï¼Œç¡®ä¿å¯è¿½è¸ªï¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from loguru import logger

# ç§»é™¤é»˜è®¤ handlerï¼Œé‡æ–°é…ç½®
logger.remove()
# ç»ˆç«¯è¾“å‡º (å½©è‰²)
logger.add(sys.stderr, level="DEBUG", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>")
# æ–‡ä»¶è¾“å‡º (è¯¦ç»†)
LOG_FILE = "/tmp/cv2_new.log"
logger.add(LOG_FILE, level="DEBUG", format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {message}", rotation="10 MB")
logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {LOG_FILE}")

# æ·»åŠ  CosyVoice åˆ°è·¯å¾„
sys.path.insert(0, '/workspace/models/CosyVoice')
os.chdir('/workspace/models/CosyVoice')

import numpy as np
import torch
import torchaudio
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, Response
from pydantic import BaseModel
from contextlib import asynccontextmanager
from typing import Optional
import tempfile

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é…ç½®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SERVICE_PORT = 9005
MODEL_DIR = "/workspace/models/CosyVoice/pretrained_models/iic/CosyVoice2-0___5B"
NATIVE_SAMPLE_RATE = 22050  # CosyVoice2 åŸç”Ÿé‡‡æ ·ç‡
TARGET_SAMPLE_RATE = 44100  # ç›®æ ‡é‡‡æ ·ç‡

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ç«¯å£ç®¡ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def kill_port(port: int):
    """æ€æ­»å ç”¨æŒ‡å®šç«¯å£çš„è¿›ç¨‹"""
    import subprocess
    try:
        result = subprocess.run(
            f"ss -tlnp | grep :{port} | awk '{{print $6}}' | grep -oP '(?<=pid=)\\d+' | xargs -r kill -9",
            shell=True, capture_output=True, text=True
        )
        if result.returncode == 0:
            logger.info(f"å·²æ¸…ç†ç«¯å£ {port}")
    except Exception as e:
        logger.warning(f"æ¸…ç†ç«¯å£å¤±è´¥: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è¯·æ±‚æ¨¡å‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class TTSRequest(BaseModel):
    text: str
    speaker_id: Optional[str] = None
    speed: float = 1.0

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CosyVoice2 æœåŠ¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class CosyVoice2Service:
    def __init__(self):
        self.model = None
        self.resampler = None
        self.ready = False
        self.default_speaker = None
        
    def initialize(self):
        """
        åˆå§‹åŒ– CosyVoice2 æ¨¡å‹
        ã€é‡è¦ã€‘æ¯ä¸€æ­¥éƒ½æ‰“å°è¯¦ç»†æ—¥å¿—ï¼Œæ–¹ä¾¿æ’é”™ï¼
        """
        logger.info("=" * 70)
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ– CosyVoice2 0.5B")
        logger.info("=" * 70)
        
        try:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Step 1: å¯¼å…¥æ¨¡å—
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info("[1/6] å¯¼å…¥ CosyVoice2 æ¨¡å—...")
            step_start = time.time()
            from cosyvoice.cli.cosyvoice import CosyVoice2
            logger.info(f"[1/6] âœ… æ¨¡å—å¯¼å…¥å®Œæˆ ({time.time()-step_start:.1f}s)")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Step 2: æ£€æŸ¥æ¨¡å‹ç›®å½•
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info(f"[2/6] æ£€æŸ¥æ¨¡å‹ç›®å½•: {MODEL_DIR}")
            if not os.path.exists(MODEL_DIR):
                raise FileNotFoundError(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {MODEL_DIR}")
            
            files = os.listdir(MODEL_DIR)
            logger.info(f"[2/6] âœ… æ¨¡å‹ç›®å½•å­˜åœ¨ï¼ŒåŒ…å« {len(files)} ä¸ªæ–‡ä»¶")
            for f in files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                logger.info(f"       - {f}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Step 3: åŠ è½½æ¨¡å‹ (è¿™æ˜¯æœ€è€—æ—¶çš„æ­¥éª¤)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info("[3/6] åŠ è½½ CosyVoice2 æ¨¡å‹ (fp16=True)...")
            logger.info("       â³ è¿™ä¸€æ­¥å¯èƒ½éœ€è¦ 1-3 åˆ†é’Ÿ...")
            step_start = time.time()
            
            # ä½¿ç”¨çº¿ç¨‹æ¥æ‰“å°å¿ƒè·³ï¼Œç¡®ä¿èƒ½è¿½è¸ªè¿›åº¦
            import threading
            loading_done = threading.Event()
            
            def heartbeat():
                """æ¯10ç§’æ‰“å°ä¸€æ¬¡å¿ƒè·³ï¼Œè¯æ˜æ²¡æœ‰å¡æ­»"""
                elapsed = 0
                while not loading_done.is_set():
                    time.sleep(10)
                    elapsed += 10
                    if not loading_done.is_set():
                        logger.info(f"       ğŸ’“ æ¨¡å‹åŠ è½½ä¸­... ({elapsed}s)")
            
            heartbeat_thread = threading.Thread(target=heartbeat, daemon=True)
            heartbeat_thread.start()
            
            try:
                # åŠ è½½æ¨¡å‹
                self.model = CosyVoice2(MODEL_DIR, fp16=True)
            finally:
                loading_done.set()
            
            logger.info(f"[3/6] âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({time.time()-step_start:.1f}s)")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Step 4: è·å–è¯´è¯äººåˆ—è¡¨
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info("[4/6] è·å–å¯ç”¨è¯´è¯äºº...")
            speakers = self.model.list_available_spks()
            logger.info(f"[4/6] âœ… å¯ç”¨è¯´è¯äºº: {speakers}")
            
            if speakers:
                self.default_speaker = speakers[0]
                logger.info(f"[4/6] é»˜è®¤è¯´è¯äºº: {self.default_speaker}")
            else:
                logger.warning("[4/6] âš ï¸ æ²¡æœ‰å¯ç”¨è¯´è¯äººï¼")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Step 5: åˆ›å»ºé‡é‡‡æ ·å™¨
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info(f"[5/6] åˆ›å»ºé‡é‡‡æ ·å™¨ ({NATIVE_SAMPLE_RATE} -> {TARGET_SAMPLE_RATE})...")
            self.resampler = torchaudio.transforms.Resample(
                NATIVE_SAMPLE_RATE, TARGET_SAMPLE_RATE
            ).cuda()
            logger.info("[5/6] âœ… é‡é‡‡æ ·å™¨åˆ›å»ºå®Œæˆ")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Step 6: é¢„çƒ­æ¨ç†
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info("[6/6] é¢„çƒ­æ¨ç†ä¸­...")
            step_start = time.time()
            
            if self.default_speaker:
                for _ in self.model.inference_sft("é¢„çƒ­æµ‹è¯•", self.default_speaker, stream=False):
                    pass
                warmup_time = (time.time() - step_start) * 1000
                logger.info(f"[6/6] âœ… é¢„çƒ­å®Œæˆ ({warmup_time:.0f}ms)")
            else:
                logger.warning("[6/6] âš ï¸ è·³è¿‡é¢„çƒ­ï¼ˆæ— é»˜è®¤è¯´è¯äººï¼‰")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # å®Œæˆ
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self.ready = True
            logger.info("=" * 70)
            logger.info("âœ…âœ…âœ… CosyVoice2 åˆå§‹åŒ–å®Œæˆï¼æœåŠ¡å·²å°±ç»ªï¼âœ…âœ…âœ…")
            logger.info("=" * 70)
            
        except Exception as e:
            logger.error("=" * 70)
            logger.error(f"âŒâŒâŒ CosyVoice2 åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error("=" * 70)
            import traceback
            logger.error(traceback.format_exc())
            
    def synthesize(self, text: str, speaker_id: str = None, speed: float = 1.0) -> bytes:
        """éæµå¼åˆæˆ"""
        if not self.ready:
            return b''
            
        speaker = speaker_id or self.default_speaker
        start_time = time.time()
        
        audio_chunks = []
        for output in self.model.inference_sft(text, speaker, stream=False, speed=speed):
            audio = output['tts_speech']
            audio_chunks.append(audio)
            
        if not audio_chunks:
            return b''
            
        # åˆå¹¶éŸ³é¢‘
        full_audio = torch.cat(audio_chunks, dim=1)
        
        # é‡é‡‡æ ·åˆ° 44.1kHz
        if full_audio.device.type != 'cuda':
            full_audio = full_audio.cuda()
        resampled = self.resampler(full_audio)
        
        # è½¬æ¢ä¸º 16-bit PCM
        audio_np = (resampled.cpu().numpy() * 32767).astype(np.int16)
        
        # è®¡ç®— RTF
        audio_duration = len(audio_np.flatten()) / TARGET_SAMPLE_RATE
        total_time = time.time() - start_time
        rtf = total_time / audio_duration
        
        if rtf > 0.1:
            logger.warning(f"âš ï¸ RTF={rtf:.3f} > 0.1ï¼Œæ€§èƒ½è­¦å‘Šï¼")
        else:
            logger.info(f"åˆæˆå®Œæˆ: {len(text)}å­—, {total_time*1000:.0f}ms, RTF={rtf:.3f}")
        
        # åˆ›å»º WAV
        buffer = io.BytesIO()
        with wave.open(buffer, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(TARGET_SAMPLE_RATE)
            wf.writeframes(audio_np.tobytes())
        return buffer.getvalue()
        
    def synthesize_stream(self, text: str, speaker_id: str = None, speed: float = 1.0):
        """çœŸæµå¼åˆæˆ - æ¯ç”Ÿæˆä¸€æ®µå°±ç«‹å³è¿”å›"""
        if not self.ready:
            return
            
        speaker = speaker_id or self.default_speaker
        start_time = time.time()
        chunk_count = 0
        total_audio_duration = 0
        
        logger.info(f"å¼€å§‹æµå¼åˆæˆ: {text[:20]}...")
        
        # ä½¿ç”¨ stream=True è¿›è¡ŒçœŸæµå¼
        for output in self.model.inference_sft(text, speaker, stream=True, speed=speed):
            chunk_start = time.time()
            audio = output['tts_speech']
            
            # é‡é‡‡æ ·åˆ° 44.1kHz
            if audio.device.type != 'cuda':
                audio = audio.cuda()
            resampled = self.resampler(audio)
            
            # è½¬æ¢ä¸º 16-bit PCM
            audio_np = (resampled.cpu().numpy() * 32767).astype(np.int16).flatten()
            
            chunk_count += 1
            chunk_duration = len(audio_np) / TARGET_SAMPLE_RATE
            total_audio_duration += chunk_duration
            
            # è®¡ç®—å½“å‰ chunk çš„ RTF
            chunk_time = time.time() - chunk_start
            chunk_rtf = chunk_time / chunk_duration if chunk_duration > 0 else 0
            
            if chunk_count == 1:
                ttfa = (time.time() - start_time) * 1000
                logger.info(f"TTFA: {ttfa:.0f}ms")
                
            if chunk_rtf > 0.1:
                logger.warning(f"âš ï¸ Chunk {chunk_count}: RTF={chunk_rtf:.3f} > 0.1")
                
            yield audio_np.tobytes()
            
        # æ€»ç»“
        total_time = time.time() - start_time
        overall_rtf = total_time / total_audio_duration if total_audio_duration > 0 else 0
        logger.info(f"æµå¼åˆæˆå®Œæˆ: {chunk_count} chunks, æ€»RTF={overall_rtf:.3f}")

    def synthesize_zero_shot(self, text: str, prompt_wav_path: str, prompt_text: str, speed: float = 1.0) -> bytes:
        """Zero-shot å…‹éš†åˆæˆï¼ˆéæµå¼ï¼‰"""
        if not self.ready:
            logger.error("æœåŠ¡æœªå°±ç»ª")
            return b''
        
        logger.info(f"Zero-shot åˆæˆ: '{text[:30]}...' (å‚è€ƒ: '{prompt_text[:20]}...')")
        start_time = time.time()
        
        try:
            audio_chunks = []
            for output in self.model.inference_zero_shot(
                text, 
                prompt_text, 
                prompt_wav_path, 
                stream=False, 
                speed=speed
            ):
                audio = output['tts_speech']
                audio_chunks.append(audio)
            
            if not audio_chunks:
                logger.error("æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘")
                return b''
            
            # åˆå¹¶éŸ³é¢‘
            full_audio = torch.cat(audio_chunks, dim=1)
            
            # é‡é‡‡æ ·åˆ° 44.1kHz
            if full_audio.device.type != 'cuda':
                full_audio = full_audio.cuda()
            resampled = self.resampler(full_audio)
            
            # è½¬æ¢ä¸º 16-bit PCM
            audio_np = (resampled.cpu().numpy() * 32767).astype(np.int16)
            
            # è®¡ç®— RTF
            audio_duration = len(audio_np.flatten()) / TARGET_SAMPLE_RATE
            total_time = time.time() - start_time
            rtf = total_time / audio_duration if audio_duration > 0 else 0
            
            logger.info(f"âœ… Zero-shot å®Œæˆ: {len(text)}å­—, {total_time*1000:.0f}ms, éŸ³é¢‘{audio_duration:.2f}s, RTF={rtf:.3f}")
            
            if rtf > 0.1:
                logger.warning(f"âš ï¸ RTF={rtf:.3f} > 0.1ï¼Œæ€§èƒ½è­¦å‘Šï¼")
            
            # åˆ›å»º WAV
            buffer = io.BytesIO()
            with wave.open(buffer, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(TARGET_SAMPLE_RATE)
                wf.writeframes(audio_np.tobytes())
            return buffer.getvalue()
            
        except Exception as e:
            logger.error(f"Zero-shot åˆæˆå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return b''

    def synthesize_zero_shot_stream(self, text: str, prompt_wav_path: str, prompt_text: str, speed: float = 1.0):
        """Zero-shot å…‹éš†åˆæˆï¼ˆæµå¼ï¼‰"""
        if not self.ready:
            logger.error("æœåŠ¡æœªå°±ç»ª")
            return
        
        logger.info(f"Zero-shot æµå¼åˆæˆ: '{text[:30]}...'")
        start_time = time.time()
        chunk_count = 0
        total_audio_duration = 0
        
        try:
            for output in self.model.inference_zero_shot(
                text, 
                prompt_text, 
                prompt_wav_path, 
                stream=True, 
                speed=speed
            ):
                chunk_start = time.time()
                audio = output['tts_speech']
                
                # é‡é‡‡æ ·åˆ° 44.1kHz
                if audio.device.type != 'cuda':
                    audio = audio.cuda()
                resampled = self.resampler(audio)
                
                # è½¬æ¢ä¸º 16-bit PCM
                audio_np = (resampled.cpu().numpy() * 32767).astype(np.int16).flatten()
                
                chunk_count += 1
                chunk_duration = len(audio_np) / TARGET_SAMPLE_RATE
                total_audio_duration += chunk_duration
                
                if chunk_count == 1:
                    ttfa = (time.time() - start_time) * 1000
                    logger.info(f"âš¡ TTFA: {ttfa:.0f}ms")
                
                yield audio_np.tobytes()
                
            # æ€»ç»“
            total_time = time.time() - start_time
            overall_rtf = total_time / total_audio_duration if total_audio_duration > 0 else 0
            logger.info(f"âœ… Zero-shot æµå¼å®Œæˆ: {chunk_count} chunks, æ€»RTF={overall_rtf:.3f}")
            
        except Exception as e:
            logger.error(f"Zero-shot æµå¼åˆæˆå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å…¨å±€å®ä¾‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
service = CosyVoice2Service()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FastAPI åº”ç”¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"ğŸ¤ CosyVoice2 æœåŠ¡å¯åŠ¨ä¸­ (ç«¯å£ {SERVICE_PORT})...")
    service.initialize()
    yield
    logger.info("ğŸ›‘ CosyVoice2 æœåŠ¡å…³é—­")

app = FastAPI(title="CosyVoice2 TTS Service", lifespan=lifespan)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health():
    return {
        "service": "mouth-cosyvoice2",
        "status": "ready" if service.ready else "loading",
        "model": "CosyVoice2 0.5B (fp16=True)",
        "sample_rate": TARGET_SAMPLE_RATE,
        "native_sample_rate": NATIVE_SAMPLE_RATE,
        "speakers": service.model.list_available_spks() if service.model else [],
        "default_speaker": service.default_speaker
    }

@app.post("/tts")
async def tts(
    text: str = Form(...),
    prompt_text: str = Form(...),
    prompt_audio: UploadFile = File(...),
    speed: float = Form(1.0)
):
    """
    Zero-shot TTSï¼ˆéæµå¼ï¼‰
    
    éœ€è¦ä¸Šä¼ å‚è€ƒéŸ³é¢‘å’Œå‚è€ƒæ–‡æœ¬æ¥å…‹éš†å£°éŸ³
    """
    if not service.ready:
        logger.error("æœåŠ¡æœªå°±ç»ª")
        return Response(content=b'Service not ready', status_code=503)
    
    try:
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            content = await prompt_audio.read()
            tmp.write(content)
            tmp_path = tmp.name
        
        logger.info(f"æ¥æ”¶åˆ° TTS è¯·æ±‚: text='{text[:30]}...', prompt_text='{prompt_text[:20]}...', prompt_audio={len(content)} bytes")
        
        # åˆæˆ
        audio = service.synthesize_zero_shot(text, tmp_path, prompt_text, speed)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_path)
        
        if not audio:
            return Response(content=b'Synthesis failed', status_code=500)
        
        return Response(content=audio, media_type="audio/wav")
        
    except Exception as e:
        logger.error(f"TTS è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return Response(content=str(e).encode(), status_code=500)

@app.post("/tts/stream")
async def tts_stream(
    text: str = Form(...),
    prompt_text: str = Form(...),
    prompt_audio: UploadFile = File(...),
    speed: float = Form(1.0)
):
    """
    Zero-shot TTSï¼ˆçœŸæµå¼ï¼‰- æ¯ç”Ÿæˆçº¦ 50ms å°±ç«‹å³è¿”å›
    """
    if not service.ready:
        logger.error("æœåŠ¡æœªå°±ç»ª")
        return Response(content=b'Service not ready', status_code=503)
    
    try:
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            content = await prompt_audio.read()
            tmp.write(content)
            tmp_path = tmp.name
        
        logger.info(f"æ¥æ”¶åˆ°æµå¼ TTS è¯·æ±‚: text='{text[:30]}...', prompt_audio={len(content)} bytes")
        
        def generate():
            try:
                for chunk in service.synthesize_zero_shot_stream(text, tmp_path, prompt_text, speed):
                    yield chunk
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(tmp_path)
                except:
                    pass
        
        return StreamingResponse(
            generate(),
            media_type="audio/pcm",
            headers={
                "X-Sample-Rate": str(TARGET_SAMPLE_RATE),
                "X-Channels": "1",
                "X-Bit-Depth": "16"
            }
        )
        
    except Exception as e:
        logger.error(f"æµå¼ TTS è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return Response(content=str(e).encode(), status_code=500)

@app.get("/speakers")
async def list_speakers():
    """è·å–å¯ç”¨è¯´è¯äººåˆ—è¡¨"""
    if not service.model:
        return {"speakers": []}
    return {"speakers": service.model.list_available_spks()}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å…¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    import uvicorn
    
    # æ¸…ç†ç«¯å£
    kill_port(SERVICE_PORT)
    
    logger.info(f"ğŸš€ å¯åŠ¨ CosyVoice2 æœåŠ¡ (ç«¯å£ {SERVICE_PORT})...")
    uvicorn.run(app, host="0.0.0.0", port=SERVICE_PORT, log_level="info")
