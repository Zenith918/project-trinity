"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ‘„ CORTEX-MOUTH-DAILY (ç«¯å£ 9003)                                            â•‘
â•‘  VoxCPM 1.5 - æè‡´ä½å»¶è¿Ÿé…ç½®                                                  â•‘
â•‘                                                                              â•‘
â•‘  ğŸ”¥ optimize=True + ç¦ç”¨ CUDA Graph = TTFA ~285ms (æ¯” optimize=False å¿« 37%)   â•‘
â•‘  ğŸ’¡ é¦–æ¬¡æµå¼è°ƒç”¨ä¼šè§¦å‘ JIT ç¼–è¯‘ (~13ç§’)ï¼Œä¹‹åç¨³å®šåœ¨ ~285ms                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
# ğŸ”‘ å…³é”®ï¼šåœ¨å¯¼å…¥ torch ä¹‹å‰ç¦ç”¨ CUDA Graph
os.environ['TORCHINDUCTOR_CUDAGRAPHS'] = '0'

import torch
# åŒé‡ä¿é™©ï¼šé€šè¿‡ config ç¦ç”¨
torch._inductor.config.triton.cudagraphs = False

import io
import wave
import numpy as np
from loguru import logger
from fastapi import FastAPI
from fastapi.responses import StreamingResponse, Response
from contextlib import asynccontextmanager
import time

mouth = None


class DailyMouthHandler:
    """VoxCPM 1.5 å¤„ç†å™¨ - optimize=True + ç¦ç”¨ CUDA Graph"""
    
    def __init__(self):
        self.model = None
        self.is_ready = False
        self.sample_rate = 24000
        self.config = {"steps": 2, "cfg_value": 1.0}
        
    async def initialize(self):
        logger.info("=" * 60)
        logger.info("æ­£åœ¨åˆå§‹åŒ– VoxCPM 1.5 (optimize=True, cudagraphs=False)...")
        logger.info("=" * 60)
        
        try:
            from voxcpm import VoxCPM
            
            # ğŸ”¥ å¯ç”¨ torch.compile ä¼˜åŒ–
            self.model = VoxCPM.from_pretrained(
                hf_model_id="openbmb/VoxCPM1.5",
                load_denoiser=False,
                optimize=True,
            )
            
            # é¢„çƒ­ 1: éæµå¼
            logger.info("é¢„çƒ­ 1/2: éæµå¼æ¨ç†...")
            _ = self.model.generate(
                text="é¢„çƒ­",
                inference_timesteps=self.config["steps"],
                cfg_value=self.config["cfg_value"],
            )
            
            # é¢„çƒ­ 2: æµå¼ (è§¦å‘å®Œæ•´ JIT)
            logger.info("é¢„çƒ­ 2/2: æµå¼æ¨ç† (è§¦å‘ JIT ç¼–è¯‘, çº¦ 13 ç§’)...")
            for chunk in self.model.generate_streaming(
                text="æµå¼é¢„çƒ­",
                inference_timesteps=self.config["steps"],
                cfg_value=self.config["cfg_value"],
            ):
                pass
            
            self.is_ready = True
            logger.success("âœ… VoxCPM 1.5 åˆå§‹åŒ–å®Œæˆ (TTFA ~285ms)")
            return True
            
        except Exception as e:
            logger.error(f"VoxCPM åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def synthesize(self, text, inference_timesteps=None, cfg_value=None):
        if not self.is_ready:
            return b""
        steps = inference_timesteps or self.config["steps"]
        cfg = cfg_value or self.config["cfg_value"]
        try:
            start = time.time()
            audio = self.model.generate(text=text, cfg_value=cfg, inference_timesteps=steps)
            logger.info(f"ç”Ÿæˆ: {len(text)}å­—, {(time.time()-start)*1000:.0f}ms")
            audio_int16 = (audio * 32767).astype(np.int16)
            buf = io.BytesIO()
            with wave.open(buf, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(self.sample_rate)
                wf.writeframes(audio_int16.tobytes())
            return buf.getvalue()
        except Exception as e:
            logger.error(f"æ¨ç†å¤±è´¥: {e}")
            return b""

    def synthesize_stream(self, text, inference_timesteps=None, cfg_value=None):
        if not self.is_ready:
            yield b""
            return
        steps = inference_timesteps or self.config["steps"]
        cfg = cfg_value or self.config["cfg_value"]
        try:
            start = time.time()
            first = True
            for chunk in self.model.generate_streaming(text=text, cfg_value=cfg, inference_timesteps=steps):
                if first:
                    logger.info(f"TTFA: {(time.time()-start)*1000:.0f}ms")
                    first = False
                chunk_int16 = (chunk * 32767).astype(np.int16)
                yield chunk_int16.tobytes()
        except Exception as e:
            logger.error(f"æµå¼å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            yield b""


@asynccontextmanager
async def lifespan(app: FastAPI):
    global mouth
    logger.info("ğŸ‘„ Cortex-Mouth-Daily å¯åŠ¨ä¸­...")
    mouth = DailyMouthHandler()
    await mouth.initialize()
    if mouth.is_ready:
        logger.success("âœ… Mouth-Daily å°±ç»ª (ç«¯å£ 9003)")
    yield
    logger.info("ğŸ›‘ Mouth-Daily å…³é—­")


app = FastAPI(lifespan=lifespan, title="Cortex-Mouth-Daily")


@app.get("/health")
async def health():
    return {
        "service": "mouth-daily",
        "status": "ok" if mouth and mouth.is_ready else "loading",
        "model": "VoxCPM 1.5 (optimized, cudagraph=off)",
        "sample_rate": 24000,
        "ttfa_target": "~285ms",
        "config": mouth.config if mouth else {}
    }


@app.post("/tts")
async def tts(request: dict):
    if not mouth or not mouth.is_ready:
        return {"error": "Not ready"}
    text = request.get("text", "")
    if not text:
        return {"error": "text required"}
    audio = mouth.synthesize(text, request.get("inference_timesteps"), request.get("cfg_value"))
    if not audio:
        return {"error": "failed"}
    return Response(content=audio, media_type="audio/wav")


@app.post("/tts/stream")
async def tts_stream(request: dict):
    if not mouth or not mouth.is_ready:
        return {"error": "Not ready"}
    text = request.get("text", "")
    if not text:
        return {"error": "text required"}
    return StreamingResponse(
        mouth.synthesize_stream(text, request.get("inference_timesteps"), request.get("cfg_value")),
        media_type="audio/pcm",
        headers={"X-Sample-Rate": "24000"}
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=9003)
