"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ‘„ CORTEX-MOUTH-DAILY (ç«¯å£ 9003)                                            â•‘
â•‘  VoxCPM 1.5 - æè‡´ä½å»¶è¿Ÿé…ç½®                                                  â•‘
â•‘                                                                              â•‘
â•‘  æ³¨æ„: optimize=False ä»¥æ”¯æŒæµå¼è¾“å‡º                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import io
import wave
import numpy as np
import torch
from loguru import logger
from fastapi import FastAPI
from fastapi.responses import StreamingResponse, Response
from contextlib import asynccontextmanager
from typing import Optional, Generator
import time

# å…¨å±€å®ä¾‹
mouth = None


class DailyMouthHandler:
    """VoxCPM 1.5 å¤„ç†å™¨"""
    
    def __init__(self):
        self.model = None
        self.is_ready = False
        self.sample_rate = 24000
        
        # é…ç½®
        self.config = {
            "steps": 2,
            "cfg_value": 1.0,
        }
        
    async def initialize(self):
        logger.info("=" * 60)
        logger.info("æ­£åœ¨åˆå§‹åŒ– VoxCPM 1.5...")
        logger.info("=" * 60)
        
        try:
            from voxcpm import VoxCPM
            
            # åŠ è½½æ¨¡å‹ - ç¦ç”¨ optimize ä»¥æ”¯æŒæµå¼
            self.model = VoxCPM.from_pretrained(
                hf_model_id="openbmb/VoxCPM1.5",
                load_denoiser=False,
                optimize=False,  # å…³é”®ï¼šç¦ç”¨ä»¥æ”¯æŒæµå¼
            )
            
            # é¢„çƒ­
            logger.info("é¢„çƒ­æ¨ç†...")
            _ = self.model.generate(
                text="é¢„çƒ­æµ‹è¯•",
                inference_timesteps=self.config["steps"],
                cfg_value=self.config["cfg_value"],
            )
            
            self.is_ready = True
            logger.success("âœ… VoxCPM 1.5 åˆå§‹åŒ–å®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"VoxCPM åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def synthesize(self, text: str, inference_timesteps: int = None, cfg_value: float = None) -> bytes:
        """ä¸€æ¬¡æ€§åˆæˆ"""
        if not self.is_ready:
            return b""
        
        steps = inference_timesteps or self.config["steps"]
        cfg = cfg_value or self.config["cfg_value"]
            
        try:
            start_time = time.time()
            
            audio = self.model.generate(
                text=text,
                cfg_value=cfg,
                inference_timesteps=steps,
            )
            
            elapsed = (time.time() - start_time) * 1000
            logger.info(f"ç”Ÿæˆå®Œæˆ: {len(text)}å­—, {elapsed:.0f}ms")
            
            # è½¬æ¢ä¸º WAV
            audio_int16 = (audio * 32767).astype(np.int16)
            buffer = io.BytesIO()
            with wave.open(buffer, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(self.sample_rate)
                wf.writeframes(audio_int16.tobytes())
            
            return buffer.getvalue()
            
        except Exception as e:
            logger.error(f"æ¨ç†å¤±è´¥: {e}")
            return b""

    def synthesize_stream(self, text: str, inference_timesteps: int = None, cfg_value: float = None):
        """æµå¼åˆæˆ"""
        if not self.is_ready:
            yield b""
            return
        
        steps = inference_timesteps or self.config["steps"]
        cfg = cfg_value or self.config["cfg_value"]
            
        try:
            start_time = time.time()
            first_chunk = True
            
            for chunk in self.model.generate_streaming(
                text=text,
                cfg_value=cfg,
                inference_timesteps=steps,
            ):
                if first_chunk:
                    ttfa = (time.time() - start_time) * 1000
                    logger.info(f"TTFA: {ttfa:.0f}ms")
                    first_chunk = False
                
                chunk_int16 = (chunk * 32767).astype(np.int16)
                yield chunk_int16.tobytes()
                
        except Exception as e:
            logger.error(f"æµå¼æ¨ç†å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            yield b""


@asynccontextmanager
async def lifespan(app: FastAPI):
    global mouth
    logger.info("ğŸ‘„ Cortex-Mouth-Daily å¯åŠ¨ä¸­...")
    
    mouth = DailyMouthHandler()
    await mouth.initialize()
    
    if mouth.is_ready:
        logger.success("âœ… Mouth-Daily å°±ç»ª (ç«¯å£ 9003)")
    
    yield
    logger.info("ğŸ›‘ Mouth-Daily å…³é—­ä¸­...")


app = FastAPI(lifespan=lifespan, title="Cortex-Mouth-Daily")


@app.get("/health")
async def health():
    return {
        "service": "mouth-daily",
        "status": "ok" if mouth and mouth.is_ready else "loading",
        "model": "VoxCPM 1.5",
        "sample_rate": 24000,
        "config": mouth.config if mouth else {}
    }


@app.post("/tts")
async def tts(request: dict):
    if not mouth or not mouth.is_ready:
        return {"error": "Mouth not ready"}
    
    text = request.get("text", "")
    if not text:
        return {"error": "text is required"}
    
    inference_timesteps = request.get("inference_timesteps")
    cfg_value = request.get("cfg_value")
    
    audio_bytes = mouth.synthesize(text, inference_timesteps, cfg_value)
    
    if not audio_bytes:
        return {"error": "Synthesis failed"}
    
    return Response(content=audio_bytes, media_type="audio/wav")


@app.post("/tts/stream")
async def tts_stream(request: dict):
    if not mouth or not mouth.is_ready:
        return {"error": "Mouth not ready"}
    
    text = request.get("text", "")
    if not text:
        return {"error": "text is required"}
    
    inference_timesteps = request.get("inference_timesteps")
    cfg_value = request.get("cfg_value")
    
    return StreamingResponse(
        mouth.synthesize_stream(text, inference_timesteps, cfg_value),
        media_type="audio/pcm",
        headers={"X-Sample-Rate": "24000"}
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=9003)
