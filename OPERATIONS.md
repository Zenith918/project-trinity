# ğŸ”® Project Trinity è¿ç»´æ‰‹å†Œ

> **é‡è¦**: æœ¬æ–‡æ¡£è®°å½•äº†æ‰€æœ‰å…³é”®é…ç½®ã€è¸©å‘è®°å½•å’Œå¯åŠ¨æµç¨‹ã€‚
> ä»»ä½• AI Agent æˆ–å¼€å‘è€…åœ¨æ“ä½œæœ¬é¡¹ç›®å‰ï¼Œè¯·**åŠ¡å¿…é€šè¯»æœ¬æ–‡æ¡£**ã€‚

---

## ğŸ“ ç³»ç»Ÿæ¶æ„

### å¾®æœåŠ¡æ¶æ„ (æ¨è)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RunPod Environment                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚   Cortex Model Server       â”‚  â”‚   Trinity Logic Server      â”‚
â”‚  â”‚   (Port 9000)               â”‚  â”‚   (Port 8000)               â”‚
â”‚  â”‚                             â”‚  â”‚                             â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â”‚ Brain (Qwen VL)     â”‚   â”‚  â”‚  â”‚ Remote Brain Client â”‚   â”‚
â”‚  â”‚  â”‚ ~14GB VRAM          â”‚   â”‚â—„â”€â”¼â”€â”€â”‚ (HTTP â†’ Cortex)     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚                             â”‚  â”‚                             â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â”‚ Mouth (CosyVoice 3) â”‚   â”‚  â”‚  â”‚ Remote Mouth Client â”‚   â”‚
â”‚  â”‚  â”‚ ~2GB VRAM           â”‚   â”‚â—„â”€â”¼â”€â”€â”‚ (HTTP â†’ Cortex)     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚                             â”‚  â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                    â”‚  â”‚ Voice (SenseVoice)  â”‚   â”‚
â”‚         æ¨¡å‹å¸¸é©»å†…å­˜                â”‚  â”‚ Local, ~1GB         â”‚   â”‚
â”‚         é‡å¯ Logic ä¸å½±å“           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                             â”‚
â”‚                                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                    â”‚  â”‚ Driver (GeneFace)   â”‚   â”‚
â”‚                                    â”‚  â”‚ Local               â”‚   â”‚
â”‚                                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                             â”‚
â”‚                                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                    â”‚  â”‚ Mind Engine         â”‚   â”‚
â”‚                                    â”‚  â”‚ BioState, Narrative â”‚   â”‚
â”‚                                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                             â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                                  â”‚
â”‚  nginx (ç³»ç»Ÿè¿›ç¨‹ï¼Œå ç”¨ 8001) â† ä¸è¦ä½¿ç”¨æ­¤ç«¯å£ï¼                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸ºä»€ä¹ˆç”¨å¾®æœåŠ¡ï¼Ÿ

| åœºæ™¯ | å•ä½“æ¨¡å¼ | å¾®æœåŠ¡æ¨¡å¼ |
|------|---------|-----------|
| ä¿®æ”¹ä¸šåŠ¡é€»è¾‘åé‡å¯ | é‡æ–°åŠ è½½æ‰€æœ‰æ¨¡å‹ (~10åˆ†é’Ÿ) | åªé‡å¯ Logic Server (~30ç§’) |
| Pod ä¼‘çœ å”¤é†’ | å…¨éƒ¨é‡æ–°åŠ è½½ | Cortex å¯å•ç‹¬å¯åŠ¨ |
| è°ƒè¯•è¿­ä»£ | ç—›è‹¦ | å¿«é€Ÿ |

---

## ğŸ—‚ï¸ å…³é”®è·¯å¾„

### æ¨¡å‹å­˜å‚¨ (Network Volume)

```
/workspace/models/
â”œâ”€â”€ Qwen2.5-VL-7B-Instruct-AWQ/    # Brain ä¸»æ¨¡å‹ (~8GB)
â”œâ”€â”€ CosyVoice3-0.5B/                # Mouth ä¸»æ¨¡å‹ (~2GB)
â”‚   â”œâ”€â”€ cosyvoice3.yaml             # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.json                 # Qwen2-0.5B é…ç½® (é‡è¦!)
â”‚   â”œâ”€â”€ model.safetensors           # Qwen2-0.5B æƒé‡
â”‚   â””â”€â”€ CosyVoice-BlankEN/          # ç©ºç™½éŸ³é¢‘èµ„æº
â”œâ”€â”€ SenseVoiceSmall/                # Voice æ¨¡å‹ (~1GB)
â””â”€â”€ LivePortrait_Weights/           # Driver æ¨¡å‹
```

### ä»£ç ä½ç½®

```
/workspace/project-trinity/project-trinity/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.py                     # Logic Server å…¥å£
â”‚   â”œâ”€â”€ cortex/
â”‚   â”‚   â”œâ”€â”€ main.py                 # Cortex Model Server å…¥å£
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ brain.py            # Qwen VL Handler
â”‚   â”‚       â””â”€â”€ mouth.py            # CosyVoice Handler
â”‚   â””â”€â”€ adapters/
â”‚       â”œâ”€â”€ brain_adapter.py        # æ”¯æŒ remote_url æ¨¡å¼
â”‚       â””â”€â”€ mouth_adapter.py        # æ”¯æŒ remote_url æ¨¡å¼
â”œâ”€â”€ run_microservices.sh            # ä¸€é”®å¯åŠ¨è„šæœ¬
â””â”€â”€ OPERATIONS.md                   # æœ¬æ–‡æ¡£
```

### Conda ç¯å¢ƒ

```
/workspace/envs/
â”œâ”€â”€ brain_env/     # ä¸»ç¯å¢ƒ (Cortex + Logic Server éƒ½ç”¨è¿™ä¸ª)
â”œâ”€â”€ face_env/      # LivePortrait ä¸“ç”¨
â””â”€â”€ voice_env/     # å¤‡ç”¨
```

### CosyVoice ä¾èµ–

```
/workspace/CosyVoice/               # CosyVoice æºç  (å¿…é¡»åœ¨ sys.path ä¸­)
â””â”€â”€ third_party/Matcha-TTS/         # Matcha-TTS ä¾èµ– (ä¹Ÿå¿…é¡»åœ¨ sys.path ä¸­)
```

---

## ğŸš€ å¯åŠ¨æµç¨‹

### æ–¹å¼ä¸€ï¼šä¸€é”®å¯åŠ¨ (æ¨è)

```bash
cd /workspace/project-trinity/project-trinity
./scripts/run_microservices.sh
```

### æ–¹å¼äºŒï¼šæ‰‹åŠ¨å¯åŠ¨

**Step 1: å¯åŠ¨ Cortex Model Server**
```bash
cd /workspace/project-trinity/project-trinity
export PYTHONPATH="$(pwd)/server:/workspace/CosyVoice:/workspace/CosyVoice/third_party/Matcha-TTS:$PYTHONPATH"
/workspace/envs/brain_env/bin/uvicorn server.cortex.main:app --host 0.0.0.0 --port 9000
```

ç­‰å¾…çœ‹åˆ°ï¼š
```
âœ… Cortex Server å°±ç»ª
INFO:     Uvicorn running on http://0.0.0.0:9000
```

**Step 2: å¯åŠ¨ Trinity Logic Server**
```bash
cd /workspace/project-trinity/project-trinity
export TRINITY_MODE="microservice"
export CORTEX_URL="http://localhost:9000"
export PYTHONPATH="$(pwd)/server:/workspace/CosyVoice:$PYTHONPATH"
/workspace/envs/brain_env/bin/uvicorn server.main:app --host 0.0.0.0 --port 8000
```

ç­‰å¾…çœ‹åˆ°ï¼š
```
ğŸ­ Project Trinity å‡†å¤‡å°±ç»ª!
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### éªŒè¯æœåŠ¡çŠ¶æ€

```bash
# Cortex å¥åº·æ£€æŸ¥
curl http://localhost:9000/health
# æœŸæœ›: {"status":"ok","modules":{"brain":true,"mouth":true}}

# Logic Server å¥åº·æ£€æŸ¥
curl http://localhost:8000/health
# æœŸæœ›: {"status":"healthy","components":{...all true...}}
```

---

## âš ï¸ è¸©å‘è®°å½• (Critical!)

### å‘1: ç«¯å£ 8001 è¢« nginx å ç”¨

**ç°è±¡**:
```
ERROR: [Errno 98] error while attempting to bind on address ('0.0.0.0', 8001): address already in use
```

**åŸå› **: RunPod ç¯å¢ƒçš„ nginx (PID 47) å ç”¨äº† 8001 ç«¯å£ã€‚

**è§£å†³æ–¹æ¡ˆ**: Cortex ä½¿ç”¨ç«¯å£ **9000**ï¼Œä¸è¦ä½¿ç”¨ 8001ã€‚

**å·²å®ç°**: `server/cortex/main.py` ä¸­æœ‰ Port Guard æœºåˆ¶ï¼Œå¯åŠ¨æ—¶ä¼šæ£€æŸ¥å¹¶æ¸…ç†ç«¯å£ã€‚

---

### å‘2: CosyVoice 3 å¿…é¡»ä½¿ç”¨ CosyVoice3 ç±»

**ç°è±¡**:
```
AssertionError: do not use /workspace/models/CosyVoice3-0.5B for CosyVoice initialization!
```

**åŸå› **: CosyVoice æœ‰ä¸‰ä¸ªç‰ˆæœ¬çš„ç±»ï¼š
- `CosyVoice` - ç”¨äº CosyVoice 1.x
- `CosyVoice2` - ç”¨äº CosyVoice 2.x
- `CosyVoice3` - ç”¨äº CosyVoice 3.x (æˆ‘ä»¬ç”¨çš„)

**è§£å†³æ–¹æ¡ˆ**:
```python
from cosyvoice.cli.cosyvoice import CosyVoice3
model = CosyVoice3("/workspace/models/CosyVoice3-0.5B", load_trt=False)
```

---

### å‘3: CosyVoice3 çš„ Qwen2-0.5B åŸºåº§æ¨¡å‹

**ç°è±¡**:
```
huggingface_hub.errors.HFValidationError: Repo id must use alphanumeric chars...
OSError: Error no file named pytorch_model.bin...
```

**åŸå› **: CosyVoice 3 å†…éƒ¨ä½¿ç”¨ Qwen2-0.5B ä½œä¸º LLM ç»„ä»¶ã€‚éœ€è¦ï¼š
1. `config.json` - ä¸èƒ½ä¸ºç©º `{}`
2. `model.safetensors` - æ¨¡å‹æƒé‡

**è§£å†³æ–¹æ¡ˆ**: ç¡®ä¿ `/workspace/models/CosyVoice3-0.5B/` ä¸‹æœ‰å®Œæ•´çš„ Qwen2-0.5B æ–‡ä»¶ï¼š
```bash
# å¦‚æœç¼ºå¤±ï¼Œä» HuggingFace ä¸‹è½½
huggingface-cli download Qwen/Qwen2-0.5B config.json model.safetensors --local-dir /workspace/models/CosyVoice3-0.5B/
```

---

### å‘4: Matcha-TTS è·¯å¾„å¿…é¡»åœ¨ sys.path

**ç°è±¡**:
```
ModuleNotFoundError: No module named 'matcha.models'
```

**åŸå› **: CosyVoice 3 ä¾èµ– Matcha-TTSï¼Œä½†å®ƒä¸åœ¨æ ‡å‡† Python è·¯å¾„ä¸­ã€‚

**è§£å†³æ–¹æ¡ˆ**: å¯åŠ¨å‰è®¾ç½® PYTHONPATHï¼š
```bash
export PYTHONPATH="/workspace/CosyVoice/third_party/Matcha-TTS:$PYTHONPATH"
```

æˆ–åœ¨ä»£ç ä¸­ï¼š
```python
import sys
sys.path.insert(0, "/workspace/CosyVoice/third_party/Matcha-TTS")
```

---

### å‘5: vLLM GPU å†…å­˜ä¸è¶³

**ç°è±¡**:
```
ValueError: Free memory on device (11.67/23.53 GiB) on startup is less than desired GPU memory utilization (0.6, 14.12 GiB).
```

**åŸå› **: æœ‰æ®‹ç•™è¿›ç¨‹å ç”¨ GPU å†…å­˜ï¼Œæˆ– `gpu_memory_utilization` è®¾ç½®è¿‡é«˜ã€‚

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥ GPU å ç”¨
nvidia-smi

# 2. æ€æ­»æ‰€æœ‰ Python è¿›ç¨‹
pkill -9 -f python
pkill -9 -f uvicorn

# 3. ç¡®è®¤ GPU æ¸…ç©º
nvidia-smi  # åº”è¯¥æ˜¾ç¤º 0MB / 24576MB

# 4. é‡æ–°å¯åŠ¨
```

**é…ç½®å‚è€ƒ** (`config.yaml`):
```yaml
model:
  qwen_gpu_memory_utilization: 0.6  # 24GB GPU è¶³å¤Ÿ
```

---

### å‘6: æ–‡ä»¶è¢«æ„å¤–æˆªæ–­/æŸå

**ç°è±¡**: `IndentationError` æˆ– `SyntaxError`

**åŸå› **: ç¼–è¾‘æ“ä½œå¯èƒ½å¯¼è‡´æ–‡ä»¶å†…å®¹è¢«æˆªæ–­ã€‚

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä» Git æ¢å¤
cd /workspace/project-trinity/project-trinity
git checkout server/main.py

# æˆ–æŸ¥çœ‹ Git diff
git diff server/main.py
```

---

## ğŸ”„ æ¢ Pod åçš„æ£€æŸ¥æ¸…å•

å½“ä½ æ¢åˆ°æ–° Pod æ—¶ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œï¼š

### 1. æ£€æŸ¥ Network Volume æŒ‚è½½
```bash
ls /workspace/models/
# åº”è¯¥çœ‹åˆ°: Qwen2.5-VL-7B-Instruct-AWQ, CosyVoice3-0.5B, SenseVoiceSmall ç­‰
```

### 2. æ£€æŸ¥ Conda ç¯å¢ƒ
```bash
ls /workspace/envs/brain_env/bin/python
# åº”è¯¥å­˜åœ¨
```

### 3. æ£€æŸ¥ CosyVoice æºç 
```bash
ls /workspace/CosyVoice/cosyvoice/cli/cosyvoice.py
# åº”è¯¥å­˜åœ¨
```

### 4. æ£€æŸ¥ä»£ç ä»“åº“
```bash
cd /workspace/project-trinity/project-trinity
git status
# åº”è¯¥æ˜¯ clean æˆ–æœ‰ä½ çš„ä¿®æ”¹
```

### 5. æ£€æŸ¥ç«¯å£å ç”¨
```bash
netstat -tlnp | grep -E "8000|8001|9000"
# 8001 å¯èƒ½è¢« nginx å ç”¨ (æ­£å¸¸)
# 8000 å’Œ 9000 åº”è¯¥ç©ºé—²
```

### 6. å¯åŠ¨æœåŠ¡
```bash
./scripts/run_microservices.sh
```

### 7. éªŒè¯
```bash
curl http://localhost:9000/health
curl http://localhost:8000/health
```

---

## ğŸ“Š ç¯å¢ƒå˜é‡å‚è€ƒ

| å˜é‡ | å€¼ | è¯´æ˜ |
|------|-----|------|
| `TRINITY_MODE` | `microservice` | å¯ç”¨å¾®æœåŠ¡æ¨¡å¼ |
| `CORTEX_URL` | `http://localhost:9000` | Cortex æœåŠ¡åœ°å€ |
| `PYTHONPATH` | è§ä¸‹ | Python æ¨¡å—æœç´¢è·¯å¾„ |

**PYTHONPATH å®Œæ•´è®¾ç½®**:
```bash
export PYTHONPATH="/workspace/project-trinity/project-trinity/server:/workspace/CosyVoice:/workspace/CosyVoice/third_party/Matcha-TTS:$PYTHONPATH"
```

---

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

### æŸ¥çœ‹æ—¥å¿—
```bash
# Cortex æ—¥å¿—
tail -f cortex_startup.log

# Logic Server æ—¥å¿—
tail -f server_startup.log
```

### é‡å¯ Logic Server (ä¸å½±å“æ¨¡å‹)
```bash
# æ€æ‰ Logic Server
pkill -f "uvicorn server.main:app"

# é‡æ–°å¯åŠ¨
export TRINITY_MODE="microservice"
export CORTEX_URL="http://localhost:9000"
cd /workspace/project-trinity/project-trinity
/workspace/envs/brain_env/bin/uvicorn server.main:app --host 0.0.0.0 --port 8000
```

### å®Œå…¨é‡å¯ (åŒ…æ‹¬æ¨¡å‹)
```bash
pkill -9 -f uvicorn
./scripts/run_microservices.sh
```

### æ£€æŸ¥ GPU çŠ¶æ€
```bash
nvidia-smi
```

---

## ğŸ“ ç‰ˆæœ¬ä¿¡æ¯

- **Qwen Model**: Qwen2.5-VL-7B-Instruct-AWQ
- **CosyVoice**: 3.0 (CosyVoice3-0.5B)
- **SenseVoice**: SenseVoiceSmall
- **vLLM**: 0.13.0
- **Python**: 3.10 (brain_env)

---

## ğŸ†˜ ç´§æ€¥æ•…éšœæ’é™¤

å¦‚æœä¸€åˆ‡éƒ½ä¸å·¥ä½œï¼Œæ‰§è¡Œ"æ ¸å¼¹é‡ç½®"ï¼š

```bash
# 1. æ€æ‰æ‰€æœ‰è¿›ç¨‹
pkill -9 -f python
pkill -9 -f uvicorn

# 2. æ¸…ç† GPU
nvidia-smi  # ç¡®è®¤æ¸…ç©º

# 3. æ¢å¤ä»£ç 
cd /workspace/project-trinity/project-trinity
git checkout .

# 4. é‡æ–°å¯åŠ¨
./scripts/run_microservices.sh
```

---

**æœ€åæ›´æ–°**: 2026-01-08
**ç»´æŠ¤è€…**: Project Trinity Team



