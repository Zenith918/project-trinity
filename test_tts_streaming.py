"""
CosyVoice 3.0 æµå¼æ¨ç†æµ‹è¯•
ç›®æ ‡: TTFT (é¦–ä¸ªéŸ³é¢‘å—) < 200ms
"""

import sys
import time
sys.path.insert(0, "/workspace/CosyVoice")
sys.path.insert(0, "/workspace/CosyVoice/third_party/Matcha-TTS")

import numpy as np

print("=" * 60)
print("CosyVoice 3.0 æµå¼æ¨ç†æµ‹è¯•")
print("=" * 60)

# 1. åŠ è½½æ¨¡å‹
print("\n[1/3] åŠ è½½ CosyVoice 3.0...")
load_start = time.time()

from cosyvoice.cli.cosyvoice import CosyVoice3
model = CosyVoice3("/workspace/models/CosyVoice3-0.5B", load_trt=False)

print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({time.time() - load_start:.1f}s)")
print(f"   é‡‡æ ·ç‡: {model.sample_rate} Hz")

# 2. åˆ›å»ºé™éŸ³å‚è€ƒéŸ³é¢‘
import wave
prompt_wav_path = "/tmp/test_prompt.wav"
sample_rate = 16000
silence = (np.random.randn(sample_rate) * 0.0001).astype(np.float32)
silence_int16 = (silence * 32767).astype(np.int16)
with wave.open(prompt_wav_path, 'w') as wf:
    wf.setnchannels(1)
    wf.setsampwidth(2)
    wf.setframerate(sample_rate)
    wf.writeframes(silence_int16.tobytes())
print(f"âœ… å‚è€ƒéŸ³é¢‘å·²åˆ›å»º")

# 3. æµ‹è¯•æµå¼æ¨ç†
test_text = "ä½ å¥½å‘€ï¼Œä»Šå¤©å¿ƒæƒ…æ€ä¹ˆæ ·ï¼Ÿ"
instruct_text = "ç”¨æ¸©æŸ”ç”œç¾çš„å¥³å£°è¯´"

print(f"\n[2/3] æµ‹è¯•éæµå¼æ¨ç† (stream=False)...")
start_time = time.time()
chunks_non_stream = []
for output in model.inference_instruct2(
    tts_text=test_text,
    instruct_text=instruct_text,
    prompt_wav=prompt_wav_path,
    stream=False
):
    if 'tts_speech' in output:
        chunks_non_stream.append(output['tts_speech'].cpu().numpy())
        first_chunk_time = time.time() - start_time
        
total_time_non_stream = time.time() - start_time
print(f"   é¦–ä¸ªéŸ³é¢‘å—: {first_chunk_time * 1000:.0f}ms")
print(f"   æ€»è€—æ—¶: {total_time_non_stream:.2f}s")
print(f"   éŸ³é¢‘å—æ•°: {len(chunks_non_stream)}")

print(f"\n[3/3] æµ‹è¯•æµå¼æ¨ç† (stream=True)...")
start_time = time.time()
first_chunk_time = None
chunks_stream = []
chunk_times = []

for output in model.inference_instruct2(
    tts_text=test_text,
    instruct_text=instruct_text,
    prompt_wav=prompt_wav_path,
    stream=True  # å…³é”®: å¼€å¯æµå¼!
):
    chunk_time = time.time() - start_time
    if 'tts_speech' in output:
        chunks_stream.append(output['tts_speech'].cpu().numpy())
        chunk_times.append(chunk_time)
        
        if first_chunk_time is None:
            first_chunk_time = chunk_time
            print(f"   ğŸ¯ é¦–ä¸ªéŸ³é¢‘å— (TTFT): {first_chunk_time * 1000:.0f}ms")

total_time_stream = time.time() - start_time

print(f"\n" + "=" * 60)
print("ğŸ“Š æµ‹è¯•ç»“æœå¯¹æ¯”")
print("=" * 60)
print(f"{'æŒ‡æ ‡':<20} {'éæµå¼':<15} {'æµå¼':<15}")
print("-" * 60)
print(f"{'TTFT (é¦–éŸ³å»¶è¿Ÿ)':<20} {first_chunk_time*1000 if chunks_non_stream else 'N/A':>10.0f}ms   {chunk_times[0]*1000 if chunk_times else 'N/A':>10.0f}ms")
print(f"{'æ€»è€—æ—¶':<20} {total_time_non_stream:>10.2f}s    {total_time_stream:>10.2f}s")
print(f"{'éŸ³é¢‘å—æ•°':<20} {len(chunks_non_stream):>10}      {len(chunks_stream):>10}")

if chunk_times:
    print(f"\nğŸ“ˆ æµå¼å—æ—¶é—´çº¿:")
    for i, t in enumerate(chunk_times[:5]):
        duration = chunks_stream[i].shape[1] / model.sample_rate * 1000
        print(f"   Chunk {i+1}: {t*1000:>6.0f}ms (éŸ³é¢‘é•¿åº¦: {duration:.0f}ms)")
    if len(chunk_times) > 5:
        print(f"   ... å…± {len(chunk_times)} ä¸ªå—")

print(f"\n{'='*60}")
if first_chunk_time and first_chunk_time < 0.2:
    print("âœ… æµå¼æ–¹æ¡ˆå¯è¡Œ! TTFT < 200ms")
elif first_chunk_time and first_chunk_time < 0.5:
    print("âš ï¸ TTFT åœ¨ 200-500msï¼Œå¯æ¥å—ä½†éœ€ä¼˜åŒ–")
else:
    print("âŒ TTFT > 500msï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
print("=" * 60)






